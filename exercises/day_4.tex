\documentclass[a4paper, 10pt]{scrartcl}

\usepackage{../generalstyle}
\usepackage{exercisestyle}


\title{Lineare Algebra II Repetitorium \\ Übungen, Tag 4}
\author{Jendrik Stelzner}
\date{\today}


\begin{document}
\maketitle


\begin{question}
  Es seien $V$ und $W$ zwei endlichdimensionale $K$-Vektorräume und $\beta \colon V \times V \to K$ und $\gamma \colon V \times V \to K$ zwei nicht-entartete symmetrische Bilinearformen.
  Es seien $\Phi_V \colon V \to V^*$, $v \mapsto \beta(-,v)$ und $\Phi_W \colon W \to W^*$, $w \mapsto \gamma(-,w)$.
  Zudem sei $f \colon V \to W$ ein $K$-lineare Abbildung und $f^T \colon W^* \to V^*$, $\psi \mapsto \psi \circ f$ die duale Abbildung.
  \begin{enumerate}[leftmargin=*]
    \item
      Zeigen Sie, dass eine Abbildung $f^* \colon W \to V$ das Diagramm
      \[
        \begin{tikzcd}[row sep = large, column sep = large, ampersand replacement=\&]
              W
              \arrow{r}{f^*}
              \arrow{d}[left]{\Phi_W}
          \&  V
              \arrow{d}{\Phi_V}
          \\
              W^*
              \arrow{r}{f^T}
          \&  V^*
        \end{tikzcd}
      \]
      genau dann zum kommutieren bringt, wenn
      \[
        \gamma(f(v), w) = \beta(v, f^*(w))
        \quad
        \text{für alle $v \in V$, $w \in W$}.
      \]
    \item
      Zeigen Sie, dass es eine eindeutige Abbildung $f^*$ gibt, die das obige Diagramm zum kommutieren bringt, und dass diese $K$-linear ist.
  \end{enumerate}
\end{question}


\begin{question}
  Es sei $V$ ein $K$-Vektorraum, $\beta \colon V \times V \to K$ eine symmetrische Bilinearform und $q \colon V \to K$, $v \mapsto \beta(v,v)$ die zugehörige quadratische Form.
  Zeigen Sie:
  \begin{enumerate}[leftmargin=*]
    \item
      Für $\ringchar(K) \neq 2$ ist
      \[
          \beta(v_1, v_2)
        = \frac{q(v_1 + v_2) - q(v_1) - q(v_2)}{2}
        \quad
        \text{für alle $v_1, v_2 \in V$}.
      \]
    \item
      Für $\ringchar(K) \neq 2$, $V \neq 0$ und $\beta$ nicht-entartet gibt es ein $v \in V$ mit $q(v) \neq 0$.
    \item
      Im Fall $\ringchar(K) = 2$ kann es verschiedene symmetrische Bilinearformen mit gleicher quadratischer Form geben.
      Geben Sie hierfür eine explizites Beispiel an.
  \end{enumerate}
\end{question}





\begin{question}
  Es seien
  \[
    A_1
    \coloneqq
    \begin{pmatrix}
      4 & 3 \\
      3 & 4
    \end{pmatrix},
    \,
    A_2
    \coloneqq
    \begin{pmatrix*}[r]
      3 &  4  \\
      4 & -3
    \end{pmatrix*},
    \,
    A_3
    \coloneqq
    \begin{pmatrix*}[r]
       3  & -2  &  0  \\
      -2  &  2  & -2  \\
       0  & -2  &  1
    \end{pmatrix*},
    \,
    A_4
    \coloneqq
    \begin{pmatrix*}[r]
       2  & -1  & 1 \\
      -1  &  2  & 1 \\
       1  &  1  & 2
    \end{pmatrix*}.
  \]
  \begin{enumerate}[leftmargin=*]
    \item
      Bestimmen Sie jeweils eine orthogonale Matrix $O_i \in \Orthogonal(n)$, so dass $O_i^T A_i O_i$ in Diagonalgestalt vorliegt.
    \item
      Entschieden Sie für die nicht-entarteten Fälle jeweils, ob es sich bei der Menge
      \[
        H_i \coloneqq \{ x \in \Reals^{n_i} \mid x^T A_i x = 10 \}
      \]
      um eine Ellipse oder eine Hyperbel bzw.\ um ein Ellipsoid oder ein einschaliges oder zweischaliges Hyperboloid handelt.
      Geben Sie jeweils die Länge der entsprechenden Hauptachsen an.
  \end{enumerate}
\end{question}


\begin{solution}
  Dritte Matrix: $T^3 - 6 T^2 + 3 T + 10$, Nullstellen $-1, 2, 5$.
  Eigenvektoren:
  \[
    \cvector{1 \\ -2 \\ 2}
    \cvector{-2 \\ -1 \\ 2}
    \cvector{1 \\ 2 \\ 2}
  \]
  Vierte Matrix: $T^3 - 6 T^2 + 9 T = T(T-3)^2$.
  Eigenvektoren (nicht orthogonal):
  \[
    \cvector{1 \\  0 \\ 1}
    \cvector{1 \\ -1 \\ 0}
    \cvector{1 \\  1 \\ 1}
  \]

\end{solution}


\begin{question}
  Entscheiden Sie, welche der folgenden Aussagen für jeden reellen Vektorraum $V$ und jede symmetrische Bilinearform $\beta \colon V \times V \to \Reals$ mit $\beta \neq 0$ gilt.
  Geben Sie gegebenenfalls ein Gegenbeispiel.
  \begin{enumerate}[leftmargin=*]
    \item
      Ist $\beta(v, v) \geq 0$ für alle $v \in V$, so ist $\beta(-, -)$ ein Skalarprodukt.
    \item
      Ist $\basis{B} \subseteq V$ eine Basis von $V$ mit $\beta(v_1, v_2) > 0$ für alle $v_1, v_2 \in \basis{B}$, so ist $\beta(-, -)$ ein Skalarprodukt.
    \item
      Für jeden Untervektorraum $U \subseteq V$ gilt $U \subseteq (U^\perp)^\perp$.
    \item
      Die Teilmengen
      \[
        U_+ \coloneqq \{ v \in V \mid \beta(v, v) \geq 0 \}
        \quad\text{und}\quad
        U_- \coloneqq \{ v \in V \mid \beta(v, v) \leq 0 \}
      \]
      sind Untervektorräume von $V$.
    \item
      Für alle Untervektorräume $U_1, U_2 \subseteq V$ gilt $(U_1 + U_2)^\perp = U_1^\perp \cap U_2^\perp$.
    \item
      Die Teilmenge $U_0 \coloneqq \{ v \in V \mid \beta(v, v) = 0 \}$ ist ein Untervektorraum von $V$.
    \item
      Ist $\dim V < \infty$, so gilt $\dim V = \dim U + \dim U^\perp$ für jeden Untervektorraum $U \subseteq V$.
    \item
      Ist $\dim V < \infty$ und $U \subseteq V$ ein Untervektorraum mit $(U^\perp)^\perp = V$, so ist $U = V$.
  \end{enumerate}
\end{question}


\begin{solution}
  \begin{enumerate}[leftmargin=*]
    \item
      Die Aussage ist falsch.
      Man betrachte etwa $\beta \colon \Reals^2 \times \Reals^2 \to \Reals$ mit
      \[
                  \beta(v, w)
        \coloneqq v^T \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix} w.
        =         v_1 w_1
      \]
      Für diese gilt $\beta(v,v) = v_1^2 \geq 0$ für alle $v \in \Reals^2$, da $\beta(e_2, e_2) = 0$ ist $\beta$ aber nicht positiv definit.
    \item
      Die Aussage ist falsch.
      Man betrachte etwa $\beta \colon \Reals^2 \times \Reals^2 \to \Reals$ mit
      \[
                  \beta(v, w)
        \coloneqq v^T \begin{pmatrix} 1 & 2 \\ 2 & 1 \end{pmatrix} w.
        =         v_1 w_1 + 2 v_1 w_2 + 2 v_2 w_1 + v_2 w_2.
      \]
      Für die Standardbasis $\basis{B} \coloneqq \{e_1, e_2\}$ gilt zwar $\beta(e_i, e_j) \in \{1, 2\}$ für alle $i,j$, da $\beta(e_1 - e_2, e_1 - e_2) = -2 < 0$ ist $\beta$ aber nicht positiv definit.
      (Da die Determinante der obigen Matrix $-3$ ist, ergibt sich auch aus dem Hauptminorenkriterium, dass $\beta$ nicht positiv definit ist.)
    \item
      Die Aussage ist stimmt.
      Ist $u \in U$ und $v \in U^\perp$, so ist $\bracket{u,v} = 0$ nach Definition von $U^\perp$, und somit $u \in (U^\perp)^\perp$.
    \item
      Die Aussage ist falsch.
      Betrachtet man etwa das vorherige Beispiel $\beta \colon \Reals^2 \to \Reals^2$ mit
      \[
                  \beta(v, w)
        \coloneqq v^T \begin{pmatrix} 1 & 2 \\ 2 & 1 \end{pmatrix} w.
        =         v_1 w_1 + 2 v_1 w_2 + 2 v_2 w_1 + v_2 w_2,
      \]
      so gilt $e_1, e_2 \in U_+$, da $\beta(e_1, e_1) = \beta(e_2, e_2) = 1 \geq 0$, aber $e_1 - e_2 \notin U_+$, da $\beta(e_1 - e_2, e_1 - e_2) = -2 < 0$.
    \item
      Die Aussage ist wahr:
      Da $U_1, U_2 \subseteq U_1 + U_2$ ist $(U_1 + U_2)^\perp \subseteq U_1^\perp, U_2^\perp$ und somit $(U_1 + U_2)^\perp \subseteq U_1^\perp \cap U_2^\perp$.
      Ist andererseits $v \in U_1^\perp \cap U_2^\perp$ und $u \in U_1 + U_2$, so gibt es $u_1 \in U_1$ und $u_2 \in U_2$ mit $u = u_1 + u_2$, weshalb
      \[
          \beta(v, u)
        = \beta(v, u_1 + u_2)
        = \beta(v, u_1) + \beta(u, v_2)
        = 0.
      \]
      Also ist auch $U_1^\perp \cap U_2^\perp \subseteq (U_1 + U_2)^\perp$.
    \item
      Die Aussage ist falsch.
      Betrachtet man etwa $\beta \colon \Reals^2 \times \Reals^2 \to \Reals$ mit
      \[
                  \beta(v, w)
        \coloneqq v \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}
        =         v_1 w_2 + v_2 w_1,
      \]
      so gilt $e_1, e_2 \in U_0$ aber $e_1 + e_2 \notin U_0$.
    \item
      Die Aussage ist falsch.
      Betrachtet man etwa $\beta \colon \Reals^2 \times \Reals^2 \to \Reals$ mit
      \[
                  \beta(v, w)
        \coloneqq v \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix}
        =         v_1 w_1,
      \]
      so gilt für den eindimensionalen Untervektorraum $U = \Ell(e_2)$, dass $U^\perp = \Reals^2$, und somit
      \[
        \dim U + \dim U^\perp = 3 > 2 = \dim \Reals^2.
      \]
      (Man hat aber stets $\dim U + \dim U^\perp \geq \dim V$.)
    \item
      Die Aussage stimmt nicht.
      Betrachtet man etwa erneut $\beta \colon \Reals^2 \times \Reals^2 \to \Reals$ mit
      \[
                  \beta(v, w)
        \coloneqq v \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix}
        =         v_1 w_1,
      \]
      so gilt für den echten Untervektorraum $U \coloneqq \Ell(e_1) \subsetneq \Reals^2$, dass $U^\perp = \Ell(e_2)$ und somit $(U^\perp)^\perp = \Reals^2$.
  \end{enumerate}
\end{solution}



\begin{question}
  Es sei $n \geq 1$.
  Es seien
  \[
    S_+ \coloneqq \{A \in \Mat_n(\Reals) \mid A^T = A\}
  \]
  der Vektorraum der symmetrischen reellen Matrizen und
  \[
    S_- \coloneqq \{A \in \Mat_n(\Reals) \mid A^T = -A\}
  \]
  der Vektorraum der schiefsymmetrischen reellen Matrizen.
  \begin{enumerate}[leftmargin=*]
    \item
      Zeigen Sie, dass $\tr(AB) = \tr(BA)$ für alle $A, B \in \Mat_n(\Reals)$.
    \item
      Zeigen Sie, dass $\sigma \colon \Mat_n(\Reals) \times \Mat_n(\Reals) \to \Reals$ mit
      \[
        \sigma(A,B) \coloneqq \tr(AB)
        \quad
        \text{für alle $A, B \in \Mat_n(\Reals)$}
      \]
      eine symmetrische Bilinearfom ist.
    \item
      Zeigen Sie, dass $\Mat_n(\Reals) = S_+ \oplus S_-$.
    \item
      Zeigen Sie, dass $S_+$ und $S_-$ orthogonal zueinander bezüglich $\sigma$ sind.
    \item
      Zeigen Sie, dass die Einschränkung $\sigma|_{S_+ \times S_+}$ positiv definit ist, und dass die Einschränkung $\sigma|_{S_- \times S_-}$ negativ definit.
    \item
      Bestimmen Sie eine Basis $\basis{C}$ von $\Mat_2(\Reals)$, so dass $\Mat_\basis{C}(\sigma)$ in Diagonalgestalt ist und $1, -1, 0$ die einzigen möglichen Diagonaleinträge sind.
  \end{enumerate}
\end{question}


\begin{question}
  Es sei $V$ ein $K$-Vektorraum mit Basis $\basis{C} = (v_1, \dotsc, v_n)$, $\basis{C}^* = (v_1^*, \dotsc, v_n^*)$ die duale Basis von $V^*$ und $\beta \colon V \times V \to K$ eine Bilinearform.
  \begin{enumerate}[leftmargin=*]
    \item
      Zeigen Sie für die lineare Abbildung $\Phi \colon V \to V^*$, $v \mapsto \beta(-,v)$, dass
      \[
        \Mat_{\basis{C}, \basis{C}^*}(\Phi)_{ij} = \beta(v_i, v_j)
        \quad
        \text{für alle $i, j = 1, \dotsc, n$}.
      \]
    \item
      Es sei $\Psi \colon V \to K^n$ der eindeutige Isomorphismus mit
      \[
          \Psi(\lambda_1 v_1 + \dotsb + \lambda_n v_n)
        = \cvector{\lambda_1 \\ \vdots \\ \lambda_n}
        \quad
        \text{für alle $\lambda_1, \dotsc, \lambda_n \in \Reals$},
      \]
      dass $\Mat_\basis{C}(\beta)$ eindeutig dadurch bestimmt ist, dass
      \[
        \beta(v, w) = \Psi(v)^T \, \Mat_\basis{C}(\beta) \, \Psi(w)
        \quad
        \text{für alle $v, w \in V$}.
      \]
    \item
      Folgern Sie, dass $\beta$ genau dann symmetrisch ist, wenn $\Mat_\basis{C}(\beta)$ symmetrisch ist.
  \end{enumerate}
\end{question}














\newpage


\printsolutions



\end{document}
